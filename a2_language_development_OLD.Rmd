---
title: "Assignment 2 (A2): Language development in autistic and neurotypical children"
subtitle: 'Instructions'
author: Maxime Sainte-Marie
output:
  html_document:
      toc: yes
      number_sections: yes
      toc_float: yes
      theme: united
      highlight: espresso
      css: '../../varia/standard.css'
  pdf_document:
    toc: no
    number_sections: yes
geometry: margin=1in
knit: (function(inputFile, encoding) {
  browseURL(
    rmarkdown::render(
      inputFile,
      encoding = encoding,
      output_dir = 'documents/assignments/instructions',
      output_file = "a2_language_development"))})
bibliography: '../../varia/bibliography.bib'
editor_options: 
  chunk_output_type: console
---
### FIX PRIORS, CHECK WHAT CHANGED? IS SIMULATION EVEN NECESSARY?
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) 

if(!'cmdstanr' %in% installed.packages()){
  remotes::install_github("stan-dev/cmdstanr")
  cmdstanr::install_cmdstan()}

pacman::p_load(
  tidyverse,
  brms,
  patchwork,
  ggplot2
)

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()

data <- read.csv("data/data_clean.csv")
```

# Intro

Autism Spectrum Disorder is often related to language impairment. However, this phenomenon has rarely been empirically traced in detail:

1. relying on actual naturalistic language production
2. over extended periods of time.

Around 30 kids with ASD and 30 typically developing kids were videotaped (matched by linguistic performance at visit 1) for ca. 30 minutes of naturalistic interactions with a parent. Data collection was repeated 6 times per kid, with 4 months between each visit. Following transcription of the data, the following quantities were computed:

1. the amount of words that each kid uses in each video. Same for the parent
2. the amount of unique words that each kid uses in each video. Same for the parent
3. .the amount of morphemes per utterance (Mean Length of Utterance) displayed by each child in each video. Same for the parent. 

This data is in the file you prepared in the previous class, but you can also find it [here](https://www.dropbox.com/s/d6eerv6cl6eksf3/data_clean.csv?dl=0)


## Assignment structure

We will be spending a few weeks with this assignment. In particular, we will:

1. build our model, analyze our empirical data, and interpret the inferential results
2. use your model to predict the linguistic trajectory of new children and assess the performance of the model based on that.

As you work through these parts, you will have to produce a written document (separated from the code) answering the following questions:

1. Briefly describe your simulation process, its goals, and what you have learned from the simulation. Add at least a plot showcasing the results of the simulation. Make a special note on sample size considerations: how much data do you think you will need? what else could you do to increase the precision of your estimates?

2. Briefly describe the empirical data and how they compare to what you learned from the simulation (what can you learn from them?). Briefly describe your model(s) and model quality. Report the findings: how does development differ between autistic and neurotypical children (N.B. remember to report both population and individual level findings)? which additional factors should be included in the model? Add at least one plot showcasing your findings.

3. Given the model(s) from Q2, how well do they predict the data? Discuss both in terms of absolute error in training vs testing; and in terms of characterizing the new kids' language development as typical or in need of support.

Below you can find more detailed instructions for each part of the assignment.

# Analysis

- Describe your sample (n, age, gender, clinical and cognitive features of the two groups) using plots and critically assess whether the groups (ASD and TD) are balanced.
####--> remember that there are the 1st visits variables added, they aren't (write this up)

- Describe linguistic development (in terms of MLU over time) in TD and ASD children (as a function of group). Discuss the difference (if any) between the two groups.
####--> TAKE INTO ACCOUNT THE VISITS, see how MLU develops over time? See how the two groups differ
# do the write up?

- Describe individual differences in linguistic development: do all kids follow the same path? Are all kids reflected by the general trend for their group?
####--> (no, some are higher functioning than others, some non-ASD children develop slower as well?)
## make a personal line for MLU or ExpressiveLangRaw per ID --> see development for each kid

- Include additional predictors in your model of language development (N.B. not other indexes of child language: types and tokens, that'd be cheating). Identify the best model, by conceptual reasoning, model comparison or a mix. Report the model you choose (and name its competitors, if any) and discuss why it's the best model.
#additional predictors such as? socialization? non-verbal and verbal iq?

In working through this part of the assignment, keep in mind the following workflow:

1. Formula definition
2. Prior definition
3. Prior predictive checking
4. Model fitting
5. Model quality checks
7. Model comparison

```{r describe_data distribution}
#Describe your sample (n, age, gender, clinical and cognitive features of the two groups) (using plots)
#critically assess whether the groups (ASD and TD) are balanced

first_visit <- data %>%
  filter(Visit == 1) 
#repetition of each visit unnecessary i think

unique_id_count <- data %>%
  summarize(unique_count = n_distinct(Child.ID))
cat("Number of unique IDs:", unique_id_count$unique_count, "\n")

last_visit <- data %>%
  filter(Visit == 6) 
```


```{r describe_data distribution}
data %>%
  group_by(Diagnosis) %>%
  summarize(Diagnosis = n())

ggplot(data, aes(x = Diagnosis, fill = Diagnosis)) +
  geom_bar() +
  labs(title = "Spread of Conditions", x = "Condition", y = "Count")

ggplot(first_visit, aes(x = Age, fill = Diagnosis)) +
  geom_histogram(binwidth = 5, color = "black") +
  labs(title = "Distribution of Age", x = "Age on visit 1", y = "Frequency") +
  guides(fill=guide_legend(title="Diagnosis"))

ggplot(first_visit, aes(x = Gender, fill = Diagnosis)) +
  geom_bar() +
  labs(title = "Distribution of Diagnoses by Gender", x = "Gender", y = "Count")

ggplot(first_visit, aes(x = Child.ID, fill = Diagnosis)) +
  geom_bar() +
  labs(title = "Distribution of Diagnoses by Ethnicity", x = "Ethnicity", y = "Count")+
  facet_wrap(~Ethnicity)
#very few ethnicities represented outside of White

first_visit %>%
  group_by(Diagnosis, Child.ID, Ethnicity) %>%
  summarize(unique_ethnicity_count = n_distinct(Ethnicity))

first_visit %>%
  group_by(Ethnicity)%>%
  count(Ethnicity)
#57 out of 66 are white, 3 more are half-white

first_visit %>%
  group_by(Gender, Diagnosis) %>%
  summarize(Count = n()) %>%
  pivot_wider(names_from = Gender, values_from = Count) %>%
  mutate(Ratio_Women = F / sum(F), Ratio_Men = M / sum(M))
#The gender ratios within ASD and TD are balanced, though the amount of females is still less by an incredible margin (this ratio balance is roughly the case W(46% ASD 55% TD) M(47% ASD, 53% TD))
```

#this is all visits
```{r describe_data}
###what are the clinical and cognitive features of the two groups?
ggplot(data, aes(x = MullenRaw, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  # Add density plot with transparency
  labs(title = "Non-verbal IQ", x = "MullenRaw", y = "Density")+
  guides(fill = guide_legend(title = "Diagnosis"))
#not as weak for the autistic individuals as their verbal iq, but still lower. Some non-diagnosed individuals however seem to be "part of the same distribution" visually as the ones diagnosed with ASD, same the other way around, though to a lesser extent
#is it not such a distinguishing aspect of autism?

ggplot(data, aes(x = ADOS, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  # Add density plot with transparency
  labs(title = "Severity of Autistic Symptoms", x = "ADOS", y = "Density")+
  guides(fill = guide_legend(title = "Diagnosis"))
#naturally, the ones diagnosed with autism are the ones with severity of autistic symptoms, checks out

ggplot(data, aes(x = ExpressiveLangRaw, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  # Add density plot with transparency
  labs(title = "Distributions of Verbal IQ", x = "ExpressiveLangRaw", y = "Density")+
  guides(fill = guide_legend(title = "Diagnosis"))
#worse for the autistic ones, some TD individuals however also seem to be "part of the same distribution" visually as the diagnosed individuals

ggplot(data, aes(x = Socialization, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  # Add density plot with transparency
  labs(title = "Distributions of Social interaction skills, responsiveness", x = "Socialization", y = "Density")+
  guides(fill = guide_legend(title = "Diagnosis"))
#worse for those with ASD overall, though some diagnosed are more "higher functioning" than others?

ggplot(data, aes(x = CHI_MLU, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  
  labs(title = "Density Plot of Mean Length of Utterance (child)", x = "MLU", y = "Density") +
  guides(fill = guide_legend(title = "Diagnosis"))
#ASD children have shorter mean length utterances

ggplot(data, aes(x = types_CHI, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  
  labs(title = "Types of unique words for children", x = "types", y = "Density") +
  guides(fill = guide_legend(title = "Diagnosis"))
#much less unique words for ASD

ggplot(data, aes(x = tokens_CHI, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  
  labs(title = "Total words for children", x = "tokens", y = "Density") +
  guides(fill = guide_legend(title = "Diagnosis"))
#less words for ASD children overall
```

#1st visit variables!!
```{r describe_data}
#1st visit variables!

ggplot(data, aes(x = ADOS1, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  # Add density plot with transparency
  labs(title = "Severity of Autistic Symptoms on visit 1", x = "ADOS", y = "Density")+
  guides(fill = guide_legend(title = "Diagnosis"))

ggplot(data, aes(x = verbalIQ1, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  # Add density plot with transparency
  labs(title = "Verbal IQ on visit 1", x = "Verbal IQ", y = "Density")+
  guides(fill = guide_legend(title = "Diagnosis"))
#overall worse for ASD, but certain ASD are "high-functioning" and certain TD are "lower-functioning" in this regard (individual differences)

ggplot(data, aes(x = nonVerbalIQ1, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  # Add density plot with transparency
  labs(title = "Non-verbal IQ on visit 1", x = "non-verbal IQ", y = "Density")+
  guides(fill = guide_legend(title = "Diagnosis"))
#not so different between the diagnoses

ggplot(data, aes(x = Socialization1, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  # Add density plot with transparency
  labs(title = "Social interaction skills and responsiveness on visit 1", x = "Socialization", y = "Density")+
  guides(fill = guide_legend(title = "Diagnosis"))
#Lower overall for ASD, but there are some more "higher-functioning" ASD individuals and some lower functioning TD (individual differences)

```

#MLU over time
```{r}
#MLU over time (visits)
ggplot(data, aes(x = Visit, y = CHI_MLU, color = Diagnosis)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, aes(group = Diagnosis)) +
  labs(title = "Development of MLU Over Time", x = "Visit", y = "Mean Length of Utterance (MLU)") +
  theme_minimal()
#roughly speaking, ASD & TD children begin with the same mean MLU, but TD children progress faster overall (higher slope). That said, there are differences between individual children, especially those diagnosed, as some are "high functioning" and match TD MLU values, and others are noticeably below: as in, "low-functioning". In the 1st visit, some ASD children even have a noticeably higher MLU than most, if not all, TD children.

#comparing distributions for 1st and last visit CHI_MLU
first_visit$Visit_Type <- "First Visit"; last_visit$Visit_Type <- "Last Visit"
first_last_combo <- rbind(first_visit, last_visit)

ggplot(first_last_combo, aes(x = CHI_MLU, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  
  labs(title = "Density Plot of Mean Length of Utterance (child)", x = "MLU", y = "Density") +
  guides(fill = guide_legend(title = "Diagnosis")) +
  facet_wrap(~Visit_Type)

first_last_combo %>%
  group_by(Diagnosis, Visit_Type) %>%
  summarize(mean_MLU = mean(CHI_MLU, na.rm = TRUE), max_MLU = max(CHI_MLU, na.rm = TRUE), min_MLU = min(CHI_MLU, na.rm = TRUE))
#the mean MLU for ASD & TD children was the same overall on 1st visit, but TD children improved on this faster, resulting in a higher mean for visit 6.
#the Max MLU for ASD children is 3.4 for the first visit, as opposed to 1.94 for the TD children (autistic utterance genius?) Though this advantage peters off.
#There appear to be some near-mute ASD children, as well (min value 0 and 0.0156 for 1st and 6th visit respectively) Comparatively, by visit 6, TD children have a min MLU of 2.07 (this is higher than the ASD mean of 1.89 by this point)

```

```{r}
#ExpressiveLangRaw per child ID (to illustrate the difference in trajectories of learning)
ggplot(data, aes(x = Visit, y = ExpressiveLangRaw, color = Diagnosis)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, aes(group = Child.ID)) +
  labs(title = "Verbal IQ Over Time, for each child", x = "Visit", y = "ExpressiveLangRaw") +
  theme_minimal()

ggplot(data, aes(x = Visit, y = ExpressiveLangRaw, color = Diagnosis)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE, aes(group = Diagnosis)) +
  labs(title = "Verbal IQ Over Time, for each child", x = "Visit", y = "ExpressiveLangRaw") +
  theme_minimal()

#there are children with downwards going data
data %>%
  filter(Visit %in% c(1, 6)) %>%  # Filter for only visits 1 and 6
  group_by(Child.ID, Visit, Diagnosis) %>%
  summarize(min_ELR = min(ExpressiveLangRaw)) %>%
  pivot_wider(names_from = Visit, values_from = min_ELR) %>%
  filter(`1` > `6`)
#2 children whose visit 6 ExpressiveLangRaw is lower than their visit 1, both ASD, slope is negative because it appears they did not significantly progress (similar values) -> slope being negative is not particularly meaningful.

data %>%
  filter(Visit %in% c(1, 6)) %>%  # Filter for only visits 1 and 6
  group_by(Child.ID, Visit, Diagnosis) %>%
  summarize(min_MLU = min(CHI_MLU)) %>%
  pivot_wider(names_from = Visit, values_from = min_MLU) %>%
  filter(`1` > `6`)
#6 children whose visit 6 MLU is lower than their visit 1, all ASD, slope is negative because it appears they did not significantly progress (similar values), as such, the fact that the slope is negative is, for most of them, not the significant part. Probably more ASD children whose MLU remained the same but whose slope is slightly positive. Still, there are two children for whom the values appeared to go down ""significantly"" (ID 23, 1 -> 0.5 & ID 36, 1.25 - 0.754)

```


```{r useless shit to cut later?}
ggplot(data, aes(x = tokens_MOT, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  
  labs(title = "Total words for mothers", x = "tokens", y = "Density") +
  guides(fill = guide_legend(title = "Diagnosis"))
#roughly the same between mothers

ggplot(data, aes(x = types_MOT, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  
  labs(title = "Types of unique words for mothers", x = "types", y = "Density") +
  guides(fill = guide_legend(title = "Diagnosis"))
#roughly the same between mothers

ggplot(data, aes(x = MOT_MLU, fill = Diagnosis)) +
  geom_density(alpha = 0.5) +  
  labs(title = "Density Plot of Mean Length of Utterance (mother)", x = "MLU", y = "Density") +
  guides(fill = guide_legend(title = "Diagnosis"))
#roughly similar, but it appears some mothers are attempting to match their ASD childrens lower MLU
```

#need to do formulas and priors, get priors from data?
#also test the models on the test data

## Formula Definition

```{r define_formulas}
#maybe change these? change the simplicity?
formula1 <-
  brms::bf(CHI_MLU ~ 1 + Visit + Diagnosis + (1 + Visit|Child.ID))

formula2 <-
  brms::bf(CHI_MLU ~ 1 + Visit + Diagnosis + (1 + Visit + MullenRaw||Child.ID))
#non-verbal IQ varies between children, individual intercepts & slopes?

formula3 <-
  brms::bf(CHI_MLU ~ 1 + Visit + Diagnosis+(1 + Visit+MullenRaw + Socialization||Child.ID))
#MullenRaw (non-verbal IQ), ExpressiveLangRaw (Verbal IQ), Socialization
#interactions, differing slopes and intercepts?
#focus on all visits or just the 1st?
```

```{r}
data %>%
  group_by(Diagnosis)%>%
  summarise(sd(MullenRaw, na.rm = T), mean(MullenRaw, na.rm = T), mean(Socialization, na.rm = T), sd(Socialization, na.rm = T),) #too similar values to be meaningful in the model?

data %>%
  group_by(Diagnosis)%>%
  summarise(sd(ExpressiveLangRaw , na.rm = T), mean(ExpressiveLangRaw, na.rm = T)) #also fairly similar
```

## Prior Definition
```{r define_priors}
#params based on "literature and assumptions", what are params for mullenraw, expresslangraw?
params <- list(
  mu_ASD = 2,
  sigma_ASD = 0.4,
  mu_TD = 2,
  sigma_TD = 0.3,
  mu_Visit_ASD = 0.4,
  sigma_Visit_ASD = 0.3,
  mu_Visit_TD = 0.6,
  sigma_Visit_TD = 0.2,
  error = 0.2)

params2 <- list(
  mu_ASD = 2,
  sigma_ASD = 0.4,
  mu_TD = 2,
  sigma_TD = 0.3,
  mu_Visit_ASD = 0.4,
  sigma_Visit_ASD = 0.3,
  mu_Visit_TD = 0.6,
  sigma_Visit_TD = 0.2,
  error = 0.2,
  mu_MullenRaw_ASD = 33,
  sd_MullenRaw_ASD = 8.7,
  mu_Socialization_ASD = 77,
  sd_Socialization_ASD = 13,
  mu_MullenRaw_TD = 35.8,
  sd_MullenRaw_TD = 9,
  mu_Socialization_TD = 102,
  sd_Socialization_TD = 9.3)

#sigma = SD
#mu = pop-mean
```

#is simulation necessary when trying to see how the model encapsulates already-existing data..?
```{r simulation this early?}
n <- 50
visits <- 6

# Define the dataset (1000 td, 1000 asd, 6 visits)
sim_data_2 <- tibble(expand.grid(Child.ID = seq(n), Diagnosis = c("ASD", "TD"), Visit = seq(visits)), intercept = NA, slope = NA)
# Make sure ASD and TD do not share a ID
sim_data_2$Child.ID[sim_data_2$Diagnosis == "TD"] <-
  sim_data_2$Child.ID[sim_data_2$Diagnosis == "TD"] + n

sim_data_2

for (i in seq(unique(sim_data_2$Child.ID))) {
  sim_data_2$intercept[sim_data_2$Child.ID == i &
                       sim_data_2$Diagnosis == "ASD"] <-
    rnorm(1, params$mu_ASD, params$sigma_ASD)
  sim_data_2$intercept[sim_data_2$Child.ID == i &
                       sim_data_2$Diagnosis == "TD"] <-
    rnorm(1, params$mu_TD, params$sigma_TD)
  sim_data_2$slope[sim_data_2$Child.ID == i &
                   sim_data_2$Diagnosis == "ASD"] <-
    rnorm(1, params$mu_Visit_ASD, params$sigma_Visit_ASD)
  sim_data_2$slope[sim_data_2$Child.ID == i &
                   sim_data_2$Diagnosis == "TD"] <-
    rnorm(1, params$mu_Visit_TD, params$sigma_Visit_TD)  
}

sim_data_2 <- sim_data_2 %>%
  mutate(
    CHI_MLU = intercept +
      (slope * (Visit - 1)) + rnorm(1, 0, params$error))

#simulating Mullenraw & Socialization
sim_data_2 <- sim_data_2 %>%
  mutate(MullenRaw = ifelse(
    Diagnosis == "ASD",
    rnorm(n, mean = params2$mu_MullenRaw_ASD, sd = params2$sd_MullenRaw_ASD),
    ifelse(
      Diagnosis == "TD",
      rnorm(n, mean = params2$mu_MullenRaw_TD, sd = params2$sd_MullenRaw_TD),
      0 
    )
  ))

sim_data_2 <- sim_data_2 %>%
  mutate(Socialization = ifelse(
    Diagnosis == "ASD",
    rnorm(n, mean = params2$mu_Socialization_ASD, sd = params2$sd_Socialization_ASD),
    ifelse(
      Diagnosis == "TD",
      rnorm(n, mean = params2$mu_Socialization_TD, sd = params2$sd_Socialization_TD),
      0 
    )
  ))

sim_data_2
#is this done correctly? simulating mullenraw per-condition so can use it in the fit
```


```{r simulation this early?}
sim_data_2

ggplot(sim_data_2, aes(Visit, CHI_MLU, color = Diagnosis)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = lm)

ggplot(sim_data_2, aes(Visit, Socialization, color = Diagnosis)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = lm)

ggplot(sim_data_2, aes(Visit, MullenRaw, color = Diagnosis)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = lm)
```

#fix these priors, understand them
```{r getting priors from formula?}
get_prior(formula1, data = sim_data_2)

priors1 <- c(
  prior(normal(1, 1), class = Intercept),
  prior(normal(0, .5), class = b),
  prior(normal(0, 1), class = sd),
  prior(normal(0, 1), class = sigma),
  prior(normal(1, 1), class = b, coef = Visit),
  prior(normal(1, 1), class = b, coef = DiagnosisTD), #literally includes diagnosis wtf?
  prior(lkj(1), class = cor)
) 

get_prior(formula2, data = sim_data_2)

priors2 <- c(
  prior(normal(1, 1), class = Intercept),
  prior(normal(0, .5), class = b), #was not used in the model due to every coefficient having individual ones already?
  prior(normal(0, 1), class = sd),
  prior(normal(0, 1), class = sigma),
  prior(normal(1, 1), class = b, coef = Visit),
  prior(normal(1, 1), class = b, coef = DiagnosisTD)
  #are these informative?
) #the 

get_prior(formula3, data = sim_data_2)

```

```{r}
#trying chatGPT priors

get_prior(formula1, data = sim_data_2)

# Define priors for your model
priors1_2 <- c(
  prior(lkj(1), class = cor),  # LKJ prior for correlations
  prior(lkj(1), class = cor, coef = Child.ID),  # LKJ prior for Child.ID correlations
  prior(student_t(3, 2.6, 2.5), class = Intercept),  # Student-t prior for Intercept
  prior(student_t(3, 0, 2.5), class = sd),  # Student-t prior for standard deviations
  prior(student_t(3, 0, 2.5), class = sd, coef = Child.ID),  # Student-t prior for Child.ID standard deviations
  prior(student_t(3, 0, 2.5), class = sd, coef = Intercept, dpar = 0),  # Student-t prior for Intercept standard deviations
  prior(student_t(3, 0, 2.5), class = sd, coef = Visit, dpar = 0),  # Student-t prior for Visit standard deviations
  prior(student_t(3, 0, 2.5), class = sigma)  # Student-t prior for sigma
)

priors2_2 <- c(
  prior(student_t(3, 2.6, 2.5), class = Intercept),  # Student-t prior for Intercept
  prior(student_t(3, 0, 2.5), class = sd),  # Student-t prior for standard deviations
  prior(student_t(3, 0, 2.5), class = sd, coef = Child.ID),  # Student-t prior for Child.ID standard deviations
  prior(student_t(3, 0, 2.5), class = sd, coef = Intercept, dpar = 0),  # Student-t prior for Intercept standard deviations
  prior(student_t(3, 0, 2.5), class = sd, coef = MullenRaw, dpar = 0),  # Student-t prior for MullenRaw standard deviations
  prior(student_t(3, 0, 2.5), class = sd, coef = Visit, dpar = 0),  # Student-t prior for Visit standard deviations
  prior(student_t(3, 0, 2.5), class = sigma)  # Student-t prior for sigma
)
```

## Prior Predictive Checking

By setting *sample_prior* parameter is set to "only" in the **brm** function, draws are drawn solely from the priors, thus ignoring the likelihood. This allows among other things to generate draws from the prior predictive distribution.

```{r }
model1_prior <- brm(
  formula1,
  sim_data_2,
  family = gaussian,
  prior = priors1,
  sample_prior = "only", #draws are drawn solely from the priors, ignoring the likelihood!
  file = 'data/model1_prior',
  backend = "cmdstanr",
  chains = 2,
  stan_model_args = list(stanc_options = list("O1"))
)
prior_predictive1 <- pp_check(model1_prior, ndraws = 100)

model2_prior <- brm(
  formula2, #is this stinkying it up?
  sim_data_2,
  family = gaussian,
  prior = priors2,
  sample_prior = "only", #draws are drawn solely from the priors, ignoring the likelihood!
  file = 'data/model2_prior',
  backend = "cmdstanr",
  chains = 2,
  stan_model_args = list(stanc_options = list("O1"))
) #this looks stinky af
prior_predictive2 <- pp_check(model2_prior, ndraws = 100)

prior_predictive1 + prior_predictive2

```

#trying auto_priors for priors
```{r}
pacman::p_load(
sjstats
)

auto_priors1 <- sjstats::auto_prior(formula1, sim_data_2, TRUE)
auto_priors2 <- sjstats::auto_prior(formula2, sim_data_2, TRUE)

auto_priors1
auto_priors2

get_prior(formula1, data = sim_data_2)
```

## Model Fitting
```{r fit_model}
# Write your code here
prior1model <- readRDS('data/model1_prior.rds')
prior2model <- readRDS('data/model2_prior.rds')
#what are these used for???

prior1model$data #what is this used for? is it used for the brm model?

prior2model$data

#this doesnt currently work since prior1model doesnt include diagnosis? yet it does? check later
model1 <- brm(
  formula1,
  #prior1model$data, #is this the right one to use? Simulation got axed?
  sim_data_2,
  family = gaussian,
  prior = prior1model$prior,
  sample_prior = T,
  file = 'data/model1_fit',
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(2),
  control = list(
    adapt_delta = 0.9,
    max_treedepth = 20
  ),
  stan_model_args = list(stanc_options = list("O1"))
)

model2 <- brm(
  formula2,
  #prior2model$data
  sim_data_2,
  family = gaussian,
  prior = prior2model$prior,
  sample_prior = T,
  file = 'data/model2_fit',
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(2),
  control = list(
    adapt_delta = 0.9,
    max_treedepth = 20
  ),
  stan_model_args = list(stanc_options = list("O1"))
)

```

## Model quality checks

```{r check_models}
# Write your code here
plot(model1)

plot(model2)
```

## Model Comparison

```{r compare_models}
# Write your code here
m1 <- add_criterion(model1, criterion = "loo")
m2 <- add_criterion(model2, criterion = "loo")
#Found 22 observations with a pareto_k > 0.7 in model 'model2'. It is recommended to set 'moment_match = TRUE' in order to perform moment matching for problematic observations.  

m1
m2

add_criterion(model1, criterion = "loo_R2")

loo_compare( m1, m2)
loo_model_weights( m1, m2)
#cant compare if differing data points (variables? more in mullenraw?)

```

```{r test_hypotheses}
# Write your code here


```


# Prediction

N.B. There are several data sets for this exercise, so pay attention to which one you are using!

1. The (training) data set from last time
2. The (test) data set on which you can test the models from last time:
  - [Demographic and clinical data](https://www.dropbox.com/s/ra99bdvm6fzay3g/demo_test.csv?dl=1)
  - [Utterance Length data](https://www.dropbox.com/s/uxtqqzl18nwxowq/LU_test.csv?dl=1)
  - [Word data](https://www.dropbox.com/s/1ces4hv8kh0stov/token_test.csv?dl=1)

Relying on the model(s) you trained in part 2 of the exercise, create predictions for the test set and assess how well they do compared to the actual data.

- Discuss the differences in performance of your model in training and testing data. Is the model any good?
- Let's assume you are a speech therapy clinic. You want to assess whether the kids in your test sample will have a typical (like a TD) development, or they will have a worse one, in which case they should get speech therapy support. What do your predictions tell you about that? Which kids would you provide therapy for? Is the model any good?

```{r import_data}
# Write your code here


```

Remove missing data to ease merging with predictions

```{r train_model}
model <- readRDS("data/model4_fit.rds")
posterior_samples <- posterior_predict(model, newdata = test_data, draws = 100, allow_new_levels = T)
predicted_values <- colMeans(posterior_samples)
head(predicted_values)
```

Assess the performance of the model on the training data: root mean square error is a good measure. (Tip: google the function rmse())

```{r assess_performance}
# Write your code here
performance::rmse(model, normalized = F, verbose = T)
#Response residuals not available to calculate mean square error. (R)MSE is probably not reliable.

```



Assess the performance of the model on the training data: root mean square error is a good measure. (Tip: google the function rmse())

```{r assess_performance}
# Write your code here


```


Show how child fare in Child MLU compared to the average TD child at each visit
```{r child_performance_td_average}
# Write your code here

```
