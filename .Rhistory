ggplot(first_visit, aes(x = Gender, fill = Diagnosis)) +
geom_bar() +
labs(title = "Distribution of Diagnoses by Gender", x = "Gender", y = "Count")
ggplot(first_visit, aes(x = Child.ID, fill = Diagnosis)) +
geom_bar() +
labs(title = "Distribution of Diagnoses by Ethnicity", x = "Ethnicity", y = "Count")+
facet_wrap(~Ethnicity)
#very few ethnicities represented outside of White
first_visit %>%
group_by(Diagnosis, Child.ID, Ethnicity) %>%
summarize(unique_ethnicity_count = n_distinct(Ethnicity))
first_visit %>%
group_by(Ethnicity)%>%
count(Ethnicity)
#57 out of 66 are white, 3 more are half-white
first_visit %>%
group_by(Gender, Diagnosis) %>%
summarize(Count = n()) %>%
pivot_wider(names_from = Gender, values_from = Count) %>%
mutate(Ratio_Women = F / sum(F), Ratio_Men = M / sum(M))
#The gender ratios within ASD and TD are balanced, though the amount of females is still less by an incredible margin (this ratio balance is roughly the case W(46% ASD 55% TD) M(47% ASD, 53% TD))
# Chunk 4: describe_data
###what are the clinical and cognitive features of the two groups?
ggplot(data, aes(x = MullenRaw, fill = Diagnosis)) +
geom_density(alpha = 0.5) +  # Add density plot with transparency
labs(title = "Non-verbal IQ", x = "MullenRaw", y = "Density")+
guides(fill = guide_legend(title = "Diagnosis"))
#not as weak for the autistic individuals as their verbal iq, but still lower. Some non-diagnosed individuals however seem to be "part of the same distribution" visually as the ones diagnosed with ASD, same the other way around, though to a lesser extent
#is it not such a distinguishing aspect of autism?
ggplot(data, aes(x = ADOS, fill = Diagnosis)) +
geom_density(alpha = 0.5) +  # Add density plot with transparency
labs(title = "Severity of Autistic Symptoms", x = "ADOS", y = "Density")+
guides(fill = guide_legend(title = "Diagnosis"))
#naturally, the ones diagnosed with autism are the ones with severity of autistic symptoms, checks out
ggplot(data, aes(x = ExpressiveLangRaw, fill = Diagnosis)) +
geom_density(alpha = 0.5) +  # Add density plot with transparency
labs(title = "Distributions of Verbal IQ", x = "ExpressiveLangRaw", y = "Density")+
guides(fill = guide_legend(title = "Diagnosis"))
#worse for the autistic ones, some TD individuals however also seem to be "part of the same distribution" visually as the diagnosed individuals
ggplot(data, aes(x = Socialization, fill = Diagnosis)) +
geom_density(alpha = 0.5) +  # Add density plot with transparency
labs(title = "Distributions of Social interaction skills, responsiveness", x = "Socialization", y = "Density")+
guides(fill = guide_legend(title = "Diagnosis"))
#worse for those with ASD overall, though some diagnosed are more "higher functioning" than others?
ggplot(data, aes(x = CHI_MLU, fill = Diagnosis)) +
geom_density(alpha = 0.5) +
labs(title = "Density Plot of Mean Length of Utterance (child)", x = "MLU", y = "Density") +
guides(fill = guide_legend(title = "Diagnosis"))
#ASD children have shorter mean length utterances
ggplot(data, aes(x = types_CHI, fill = Diagnosis)) +
geom_density(alpha = 0.5) +
labs(title = "Types of unique words for children", x = "types", y = "Density") +
guides(fill = guide_legend(title = "Diagnosis"))
#much less unique words for ASD
ggplot(data, aes(x = tokens_CHI, fill = Diagnosis)) +
geom_density(alpha = 0.5) +
labs(title = "Total words for children", x = "tokens", y = "Density") +
guides(fill = guide_legend(title = "Diagnosis"))
#less words for ASD children overall
# Chunk 5: describe_data
#1st visit variables!
ggplot(data, aes(x = ADOS1, fill = Diagnosis)) +
geom_density(alpha = 0.5) +  # Add density plot with transparency
labs(title = "Severity of Autistic Symptoms on visit 1", x = "ADOS", y = "Density")+
guides(fill = guide_legend(title = "Diagnosis"))
ggplot(data, aes(x = verbalIQ1, fill = Diagnosis)) +
geom_density(alpha = 0.5) +  # Add density plot with transparency
labs(title = "Verbal IQ on visit 1", x = "Verbal IQ", y = "Density")+
guides(fill = guide_legend(title = "Diagnosis"))
#overall worse for ASD, but certain ASD are "high-functioning" and certain TD are "lower-functioning" in this regard (individual differences)
ggplot(data, aes(x = nonVerbalIQ1, fill = Diagnosis)) +
geom_density(alpha = 0.5) +  # Add density plot with transparency
labs(title = "Non-verbal IQ on visit 1", x = "non-verbal IQ", y = "Density")+
guides(fill = guide_legend(title = "Diagnosis"))
#not so different between the diagnoses
ggplot(data, aes(x = Socialization1, fill = Diagnosis)) +
geom_density(alpha = 0.5) +  # Add density plot with transparency
labs(title = "Social interaction skills and responsiveness on visit 1", x = "Socialization", y = "Density")+
guides(fill = guide_legend(title = "Diagnosis"))
#Lower overall for ASD, but there are some more "higher-functioning" ASD individuals and some lower functioning TD (individual differences)
# Chunk 6
#MLU over time (visits)
ggplot(data, aes(x = Visit, y = CHI_MLU, color = Diagnosis)) +
geom_point() +
geom_smooth(method = "lm", formula = y ~ x, se = FALSE, aes(group = Diagnosis)) +
labs(title = "Development of MLU Over Time", x = "Visit", y = "Mean Length of Utterance (MLU)") +
theme_minimal()
#roughly speaking, ASD & TD children begin with the same mean MLU, but TD children progress faster overall (higher slope). That said, there are differences between individual children, especially those diagnosed, as some are "high functioning" and match TD MLU values, and others are noticeably below: as in, "low-functioning". In the 1st visit, some ASD children even have a noticeably higher MLU than most, if not all, TD children.
#comparing distributions for 1st and last visit CHI_MLU
first_visit$Visit_Type <- "First Visit"; last_visit$Visit_Type <- "Last Visit"
first_last_combo <- rbind(first_visit, last_visit)
ggplot(first_last_combo, aes(x = CHI_MLU, fill = Diagnosis)) +
geom_density(alpha = 0.5) +
labs(title = "Density Plot of Mean Length of Utterance (child)", x = "MLU", y = "Density") +
guides(fill = guide_legend(title = "Diagnosis")) +
facet_wrap(~Visit_Type)
first_last_combo %>%
group_by(Diagnosis, Visit_Type) %>%
summarize(mean_MLU = mean(CHI_MLU, na.rm = TRUE), max_MLU = max(CHI_MLU, na.rm = TRUE), min_MLU = min(CHI_MLU, na.rm = TRUE))
#the mean MLU for ASD & TD children was the same overall on 1st visit, but TD children improved on this faster, resulting in a higher mean for visit 6.
#the Max MLU for ASD children is 3.4 for the first visit, as opposed to 1.94 for the TD children (autistic utterance genius?) Though this advantage peters off.
#There appear to be some near-mute ASD children, as well (min value 0 and 0.0156 for 1st and 6th visit respectively) Comparatively, by visit 6, TD children have a min MLU of 2.07 (this is higher than the ASD mean of 1.89 by this point)
# Chunk 7
#ExpressiveLangRaw per child ID (to illustrate the difference in trajectories of learning)
ggplot(data, aes(x = Visit, y = ExpressiveLangRaw, color = Diagnosis)) +
geom_point() +
geom_smooth(method = "lm", formula = y ~ x, se = FALSE, aes(group = Child.ID)) +
labs(title = "Verbal IQ Over Time, for each child", x = "Visit", y = "ExpressiveLangRaw") +
theme_minimal()
ggplot(data, aes(x = Visit, y = ExpressiveLangRaw, color = Diagnosis)) +
geom_point() +
geom_smooth(method = "lm", formula = y ~ x, se = FALSE, aes(group = Diagnosis)) +
labs(title = "Verbal IQ Over Time, for each child", x = "Visit", y = "ExpressiveLangRaw") +
theme_minimal()
#there are children with downwards going data
data %>%
filter(Visit %in% c(1, 6)) %>%  # Filter for only visits 1 and 6
group_by(Child.ID, Visit, Diagnosis) %>%
summarize(min_ELR = min(ExpressiveLangRaw)) %>%
pivot_wider(names_from = Visit, values_from = min_ELR) %>%
filter(`1` > `6`)
#2 children whose visit 6 ExpressiveLangRaw is lower than their visit 1, both ASD, slope is negative because it appears they did not significantly progress (similar values) -> slope being negative is not particularly meaningful.
data %>%
filter(Visit %in% c(1, 6)) %>%  # Filter for only visits 1 and 6
group_by(Child.ID, Visit, Diagnosis) %>%
summarize(min_MLU = min(CHI_MLU)) %>%
pivot_wider(names_from = Visit, values_from = min_MLU) %>%
filter(`1` > `6`)
#6 children whose visit 6 MLU is lower than their visit 1, all ASD, slope is negative because it appears they did not significantly progress (similar values), as such, the fact that the slope is negative is, for most of them, not the significant part. Probably more ASD children whose MLU remained the same but whose slope is slightly positive. Still, there are two children for whom the values appeared to go down ""significantly"" (ID 23, 1 -> 0.5 & ID 36, 1.25 - 0.754)
# Chunk 8: useless shit to cut later?
ggplot(data, aes(x = tokens_MOT, fill = Diagnosis)) +
geom_density(alpha = 0.5) +
labs(title = "Total words for mothers", x = "tokens", y = "Density") +
guides(fill = guide_legend(title = "Diagnosis"))
#roughly the same between mothers
ggplot(data, aes(x = types_MOT, fill = Diagnosis)) +
geom_density(alpha = 0.5) +
labs(title = "Types of unique words for mothers", x = "types", y = "Density") +
guides(fill = guide_legend(title = "Diagnosis"))
#roughly the same between mothers
ggplot(data, aes(x = MOT_MLU, fill = Diagnosis)) +
geom_density(alpha = 0.5) +
labs(title = "Density Plot of Mean Length of Utterance (mother)", x = "MLU", y = "Density") +
guides(fill = guide_legend(title = "Diagnosis"))
#roughly similar, but it appears some mothers are attempting to match their ASD childrens lower MLU
# Chunk 9: define_formulas
#maybe change these? change the simplicity?
formula1 <-
brms::bf(CHI_MLU ~ 1 + Visit + Diagnosis + (1 + Visit|Child.ID))
formula2 <-
brms::bf(CHI_MLU ~ 1 + Visit + Diagnosis + (1 + Visit + MullenRaw||Child.ID))
#non-verbal IQ varies between children, individual intercepts & slopes?
formula3 <-
brms::bf(CHI_MLU ~ 1 + Visit + Diagnosis+(1 + Visit+MullenRaw + Socialization||Child.ID))
#MullenRaw (non-verbal IQ), ExpressiveLangRaw (Verbal IQ), Socialization
#interactions, differing slopes and intercepts?
#focus on all visits or just the 1st?
# Chunk 10
data %>%
group_by(Diagnosis)%>%
summarise(sd(MullenRaw, na.rm = T), mean(MullenRaw, na.rm = T), mean(Socialization, na.rm = T), sd(Socialization, na.rm = T),) #too similar values to be meaningful in the model?
data %>%
group_by(Diagnosis)%>%
summarise(sd(ExpressiveLangRaw , na.rm = T), mean(ExpressiveLangRaw, na.rm = T)) #also fairly similar
# Chunk 11: define_priors
#params based on "literature and assumptions", what are params for mullenraw, expresslangraw?
params <- list(
mu_ASD = 2,
sigma_ASD = 0.4,
mu_TD = 2,
sigma_TD = 0.3,
mu_Visit_ASD = 0.4,
sigma_Visit_ASD = 0.3,
mu_Visit_TD = 0.6,
sigma_Visit_TD = 0.2,
error = 0.2)
params2 <- list(
mu_ASD = 2,
sigma_ASD = 0.4,
mu_TD = 2,
sigma_TD = 0.3,
mu_Visit_ASD = 0.4,
sigma_Visit_ASD = 0.3,
mu_Visit_TD = 0.6,
sigma_Visit_TD = 0.2,
error = 0.2,
mu_MullenRaw_ASD = 33,
sd_MullenRaw_ASD = 8.7,
mu_Socialization_ASD = 77,
sd_Socialization_ASD = 13,
mu_MullenRaw_TD = 35.8,
sd_MullenRaw_TD = 9,
mu_Socialization_TD = 102,
sd_Socialization_TD = 9.3)
#sigma = SD
#mu = pop-mean
# Chunk 12: simulation this early?
n <- 50
visits <- 6
# Define the dataset (1000 td, 1000 asd, 6 visits)
sim_data_2 <- tibble(expand.grid(Child.ID = seq(n), Diagnosis = c("ASD", "TD"), Visit = seq(visits)), intercept = NA, slope = NA)
# Make sure ASD and TD do not share a ID
sim_data_2$Child.ID[sim_data_2$Diagnosis == "TD"] <-
sim_data_2$Child.ID[sim_data_2$Diagnosis == "TD"] + n
sim_data_2
for (i in seq(unique(sim_data_2$Child.ID))) {
sim_data_2$intercept[sim_data_2$Child.ID == i &
sim_data_2$Diagnosis == "ASD"] <-
rnorm(1, params$mu_ASD, params$sigma_ASD)
sim_data_2$intercept[sim_data_2$Child.ID == i &
sim_data_2$Diagnosis == "TD"] <-
rnorm(1, params$mu_TD, params$sigma_TD)
sim_data_2$slope[sim_data_2$Child.ID == i &
sim_data_2$Diagnosis == "ASD"] <-
rnorm(1, params$mu_Visit_ASD, params$sigma_Visit_ASD)
sim_data_2$slope[sim_data_2$Child.ID == i &
sim_data_2$Diagnosis == "TD"] <-
rnorm(1, params$mu_Visit_TD, params$sigma_Visit_TD)
}
sim_data_2 <- sim_data_2 %>%
mutate(
CHI_MLU = intercept +
(slope * (Visit - 1)) + rnorm(1, 0, params$error))
#simulating Mullenraw & Socialization
sim_data_2 <- sim_data_2 %>%
mutate(MullenRaw = ifelse(
Diagnosis == "ASD",
rnorm(n, mean = params2$mu_MullenRaw_ASD, sd = params2$sd_MullenRaw_ASD),
ifelse(
Diagnosis == "TD",
rnorm(n, mean = params2$mu_MullenRaw_TD, sd = params2$sd_MullenRaw_TD),
0
)
))
sim_data_2 <- sim_data_2 %>%
mutate(Socialization = ifelse(
Diagnosis == "ASD",
rnorm(n, mean = params2$mu_Socialization_ASD, sd = params2$sd_Socialization_ASD),
ifelse(
Diagnosis == "TD",
rnorm(n, mean = params2$mu_Socialization_TD, sd = params2$sd_Socialization_TD),
0
)
))
sim_data_2
#is this done correctly? simulating mullenraw per-condition so can use it in the fit
# Chunk 13: simulation this early?
sim_data_2
ggplot(sim_data_2, aes(Visit, CHI_MLU, color = Diagnosis)) +
geom_point(alpha = 0.2) +
geom_smooth(method = lm)
ggplot(sim_data_2, aes(Visit, Socialization, color = Diagnosis)) +
geom_point(alpha = 0.2) +
geom_smooth(method = lm)
ggplot(sim_data_2, aes(Visit, MullenRaw, color = Diagnosis)) +
geom_point(alpha = 0.2) +
geom_smooth(method = lm)
# Chunk 14: getting priors from formula?
get_prior(formula1, data = sim_data_2)
priors1 <- c(
prior(normal(1, 1), class = Intercept),
prior(normal(0, .5), class = b),
prior(normal(0, 1), class = sd),
prior(normal(0, 1), class = sigma),
prior(normal(1, 1), class = b, coef = Visit),
prior(normal(1, 1), class = b, coef = DiagnosisTD), #literally includes diagnosis wtf?
prior(lkj(1), class = cor)
)
get_prior(formula2, data = sim_data_2)
priors2 <- c(
prior(normal(1, 1), class = Intercept),
prior(normal(0, .5), class = b), #was not used in the model due to every coefficient having individual ones already?
prior(normal(0, 1), class = sd),
prior(normal(0, 1), class = sigma),
prior(normal(1, 1), class = b, coef = Visit),
prior(normal(1, 1), class = b, coef = DiagnosisTD)
#are these informative?
) #the
get_prior(formula3, data = sim_data_2)
# Chunk 15
#trying chatGPT priors
get_prior(formula1, data = sim_data_2)
# Define priors for your model
priors1_2 <- c(
prior(lkj(1), class = cor),  # LKJ prior for correlations
prior(lkj(1), class = cor, coef = Child.ID),  # LKJ prior for Child.ID correlations
prior(student_t(3, 2.6, 2.5), class = Intercept),  # Student-t prior for Intercept
prior(student_t(3, 0, 2.5), class = sd),  # Student-t prior for standard deviations
prior(student_t(3, 0, 2.5), class = sd, coef = Child.ID),  # Student-t prior for Child.ID standard deviations
prior(student_t(3, 0, 2.5), class = sd, coef = Intercept, dpar = 0),  # Student-t prior for Intercept standard deviations
prior(student_t(3, 0, 2.5), class = sd, coef = Visit, dpar = 0),  # Student-t prior for Visit standard deviations
prior(student_t(3, 0, 2.5), class = sigma)  # Student-t prior for sigma
)
priors2_2 <- c(
prior(student_t(3, 2.6, 2.5), class = Intercept),  # Student-t prior for Intercept
prior(student_t(3, 0, 2.5), class = sd),  # Student-t prior for standard deviations
prior(student_t(3, 0, 2.5), class = sd, coef = Child.ID),  # Student-t prior for Child.ID standard deviations
prior(student_t(3, 0, 2.5), class = sd, coef = Intercept, dpar = 0),  # Student-t prior for Intercept standard deviations
prior(student_t(3, 0, 2.5), class = sd, coef = MullenRaw, dpar = 0),  # Student-t prior for MullenRaw standard deviations
prior(student_t(3, 0, 2.5), class = sd, coef = Visit, dpar = 0),  # Student-t prior for Visit standard deviations
prior(student_t(3, 0, 2.5), class = sigma)  # Student-t prior for sigma
)
model1_prior <- brm(
formula1,
sim_data_2,
family = gaussian,
prior = priors1,
sample_prior = "only", #draws are drawn solely from the priors, ignoring the likelihood!
file = 'data/model1_prior',
backend = "cmdstanr",
chains = 2,
stan_model_args = list(stanc_options = list("O1"))
)
prior_predictive1 <- pp_check(model1_prior, ndraws = 100)
model2_prior <- brm(
formula2, #is this stinkying it up?
sim_data_2,
family = gaussian,
prior = priors2,
sample_prior = "only", #draws are drawn solely from the priors, ignoring the likelihood!
file = 'data/model2_prior',
backend = "cmdstanr",
chains = 2,
stan_model_args = list(stanc_options = list("O1"))
) #this looks stinky af
prior_predictive2 <- pp_check(model2_prior, ndraws = 100)
prior_predictive1 + prior_predictive2
model1_prior <- brm(
formula1,
sim_data_2,
family = gaussian,
prior = priors1,
sample_prior = "only", #draws are drawn solely from the priors, ignoring the likelihood!
file = 'data/model1_prior',
backend = "cmdstanr",
chains = 2,
stan_model_args = list(stanc_options = list("O1"))
)
prior_predictive1 <- pp_check(model1_prior, ndraws = 100)
model2_prior <- brm(
formula2, #is this stinkying it up?
sim_data_2,
family = gaussian,
prior = priors2,
sample_prior = "only", #draws are drawn solely from the priors, ignoring the likelihood!
file = 'data/model2_prior',
backend = "cmdstanr",
chains = 2,
stan_model_args = list(stanc_options = list("O1"))
) #this looks stinky af
prior_predictive2 <- pp_check(model2_prior, ndraws = 100)
prior_predictive1 + prior_predictive2
pacman::p_load(
sjstats
)
auto_priors1 <- sjstats::auto_prior(formula1, sim_data_2, TRUE)
auto_priors2 <- sjstats::auto_prior(formula2, sim_data_2, TRUE)
auto_priors1
auto_priors2
get_prior(formula1, data = sim_data_2)
# Write your code here
prior1model <- readRDS('data/model1_prior.rds')
prior2model <- readRDS('data/model2_prior.rds')
#what are these used for???
prior1model$data #what is this used for? is it used for the brm model?
prior2model$data
#this doesnt currently work since prior1model doesnt include diagnosis? yet it does? check later
model1 <- brm(
formula1,
#prior1model$data, #is this the right one to use? Simulation got axed?
sim_data_2,
family = gaussian,
prior = priors1_2,
sample_prior = T,
file = 'data/model1_fit',
backend = "cmdstanr",
chains = 2,
cores = 2,
threads = threading(2),
control = list(
adapt_delta = 0.9,
max_treedepth = 20
),
stan_model_args = list(stanc_options = list("O1"))
)
# Write your code here
prior1model <- readRDS('data/model1_prior.rds')
prior2model <- readRDS('data/model2_prior.rds')
#what are these used for???
prior1model$data #what is this used for? is it used for the brm model?
prior2model$data
#this doesnt currently work since prior1model doesnt include diagnosis? yet it does? check later
model1 <- brm(
formula1,
#prior1model$data, #is this the right one to use? Simulation got axed?
sim_data_2,
family = gaussian,
prior = priors1_2,
sample_prior = T,
file = 'data/model1_fit',
backend = "cmdstanr",
chains = 2,
cores = 2,
threads = threading(2),
control = list(
adapt_delta = 0.9,
max_treedepth = 20
),
stan_model_args = list(stanc_options = list("O1"))
)
model1_prior <- brm(
formula1,
sim_data_2,
family = gaussian,
prior = priors1,
sample_prior = "only", #draws are drawn solely from the priors, ignoring the likelihood!
file = 'data/model1_prior',
backend = "cmdstanr",
chains = 2,
stan_model_args = list(stanc_options = list("O1"))
)
prior_predictive1 <- pp_check(model1_prior, ndraws = 100)
model2_prior <- brm(
formula2, #is this stinkying it up?
sim_data_2,
family = gaussian,
prior = priors2,
sample_prior = "only", #draws are drawn solely from the priors, ignoring the likelihood!
file = 'data/model2_prior',
backend = "cmdstanr",
chains = 2,
stan_model_args = list(stanc_options = list("O1"))
) #this looks stinky af
prior_predictive2 <- pp_check(model2_prior, ndraws = 100)
prior_predictive1 + prior_predictive2
model1_prior <- brm(
formula1,
sim_data_2,
family = gaussian,
prior = priors1,
sample_prior = "only", #draws are drawn solely from the priors, ignoring the likelihood!
file = 'data/model1_prior',
backend = "cmdstanr",
chains = 2,
stan_model_args = list(stanc_options = list("O1"))
)
prior_predictive1 <- pp_check(model1_prior, ndraws = 100)
model2_prior <- brm(
formula2, #is this stinkying it up?
sim_data_2,
family = gaussian,
prior = priors2,
sample_prior = "only", #draws are drawn solely from the priors, ignoring the likelihood!
file = 'data/model2_prior',
backend = "cmdstanr",
chains = 2,
stan_model_args = list(stanc_options = list("O1"))
) #this looks stinky af
prior_predictive2 <- pp_check(model2_prior, ndraws = 100)
prior_predictive1 + prior_predictive2
# Write your code here
prior1model <- readRDS('data/model1_prior.rds')
prior2model <- readRDS('data/model2_prior.rds')
#what are these used for???
prior1model$data #what is this used for? is it used for the brm model?
prior2model$data
#this doesnt currently work since prior1model doesnt include diagnosis? yet it does? check later
model1 <- brm(
formula1,
#prior1model$data, #is this the right one to use? Simulation got axed?
sim_data_2,
family = gaussian,
prior = model1_prior$prior,
sample_prior = T,
file = 'data/model1_fit',
backend = "cmdstanr",
chains = 2,
cores = 2,
threads = threading(2),
control = list(
adapt_delta = 0.9,
max_treedepth = 20
),
stan_model_args = list(stanc_options = list("O1"))
)
View(model1_prior)
# Write your code here
prior1model <- readRDS('data/model1_prior.rds')
prior2model <- readRDS('data/model2_prior.rds')
#what are these used for???
prior1model$data #what is this used for? is it used for the brm model?
prior2model$data
#this doesnt currently work since prior1model doesnt include diagnosis? yet it does? check later
model1 <- brm(
formula1,
#prior1model$data, #is this the right one to use? Simulation got axed?
sim_data_2,
family = gaussian,
prior = prior1model$prior,
sample_prior = T,
file = 'data/model1_fit',
backend = "cmdstanr",
chains = 2,
cores = 2,
threads = threading(2),
control = list(
adapt_delta = 0.9,
max_treedepth = 20
),
stan_model_args = list(stanc_options = list("O1"))
)
get_prior(formula1, data = sim_data_2)
